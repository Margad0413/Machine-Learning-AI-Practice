{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqCOJBDb64BBwE++S/wr8v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["심층 신경망\n","\n","구성 요소\n","* 입력층(Input Layer): 입력 데이터를 받는 부분\n","* 은닉층(Hidden Layers): 여러 개의 뉴런이 연결되어 특징을 추출\n","* 출력층(Output Layer): 최종 예측 결과\n","\n","학습 절차:\n","* Forward Propagation(순전파): 입력 → 출력으로 값 전달\n","* Loss Computation(손실함수 계산): 예측값과 실제값의 차이 계산\n","* Backpropagation(역전파): 오차를 기반으로 가중치 업데이트\n","\n","은닉층이 2개부터 심층\n","\n","은닉층(hidden layer): 입력층과 출력층 사이의 모든 층. 입력층에서부터 출력층으로 노드개수가 줄어드는 방향으로 설계하는게 좋다. 노드수가 출력층보다는 많아야함.\n","\n","밀집층(dense)(완전연결층): complete 구조(모두 연결되어 있는 구조)를 말함. 앞뒤 레이어의 노드랑 빠짐없이 연결되어 있음.\n","\n","은닉층의 활성화 함수: 은닉층에서 계산된 값을 처리하는 함수. 비교적 자유로움\n","\n","출력층 활성화 함수: 소프트맥스 같은거"],"metadata":{"id":"-gFtHlQwtlHX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"id":"JnOMfHo_tjvB","executionInfo":{"status":"ok","timestamp":1763433304198,"user_tz":-540,"elapsed":24422,"user":{"displayName":"Somebody A","userId":"09642566807234292783"}},"outputId":"5f024c6f-0f35-41f1-b6a9-49c9e95779d5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"fashion\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fashion\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ hidden (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m78,500\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,500</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,510\u001b[0m (310.59 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,510</span> (310.59 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.7753\n","Epoch 2/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.4244\n","Epoch 3/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3774\n","Epoch 4/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.3589\n","Epoch 5/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.3358\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7dca8a51fec0>"]},"metadata":{},"execution_count":4}],"source":["from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","\n","(train_input, train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n","\n","train_scaled = train_input/255.0\n","train_scaled = train_scaled.reshape(-1,28*28)\n","\n","train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled,train_target,test_size=0.2,random_state=42)\n","\n","inputs = keras.layers.Input(shape=(784,)) #입력층\n","dense1 = keras.layers.Dense(100,activation='sigmoid',name='hidden') #은닉층\n","dense2 = keras.layers.Dense(10,activation='softmax',name='output') #출력층\n","model = keras.Sequential([inputs,dense1,dense2], name='fashion') #이름 한글로 적으면 오류\n","model.summary()\n","#28*28은 784인데, 값이 78,500인 이유는 28*28*100 + 100(바이어스) 구조라서 그렇다.\n","#사실상 지금 구조는 심층은 아님(은닉층이 1개라서)\n","model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","model.fit(train_scaled,train_target,epochs=5)"]},{"cell_type":"code","source":["from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","\n","(train_input, train_target),(test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n","\n","train_scaled = train_input/255.0\n","#train_scaled = train_scaled.reshape(-1,28*28)\n","\n","train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled,train_target,test_size=0.2,random_state=42)\n","\n","inputs = keras.layers.Input(shape=(28,28)) #입력층\n","flat = keras.layers.Flatten(name='flatten') #플랫층: 데이터 구조 변환용 층(무조건 1차원)\n","dense1 = keras.layers.Dense(100,activation='relu',name='hidden') #은닉층(완전연결층)\n","dense2 = keras.layers.Dense(10,activation='softmax',name='output') #출력층\n","model = keras.Sequential([inputs,flat,dense1,dense2], name='fashion') #이름 한글로 적으면 오류\n","#model.summary()\n","\n","model.compile(loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","model.fit(train_scaled,train_target,epochs=5)\n","\n","#relu함수 쓰니까 정확성이 조금 높아진다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7rFaIPkvtvpp","executionInfo":{"status":"ok","timestamp":1763616210945,"user_tz":-540,"elapsed":44577,"user":{"displayName":"Somebody A","userId":"09642566807234292783"}},"outputId":"c0d594ba-e826-4066-a086-59ab09245ef3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","Epoch 1/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7642 - loss: 0.6714\n","Epoch 2/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.4087\n","Epoch 3/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.3586\n","Epoch 4/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.3348\n","Epoch 5/5\n","\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.3137\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7b69074135f0>"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":[],"metadata":{"id":"mwUdbW6BtyBw"},"execution_count":null,"outputs":[]}]}